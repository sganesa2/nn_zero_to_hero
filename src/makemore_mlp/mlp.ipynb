{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1604a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cREATE THE DATASET\n",
    "from dataset import MLPDataset, itos, stoi\n",
    "\n",
    "dataset_obj = MLPDataset(\"dataset.txt\",470671,58833,58833,3)\n",
    "total_xs,total_ys = dataset_obj.create_complete_dataset()\n",
    "xs,ys = dataset_obj.trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import MLP\n",
    "\n",
    "context_size = 3\n",
    "mini_batch_size = xs.shape[0]\n",
    "\n",
    "minibatch_tensor = torch.randint(0, xs.shape[0], (mini_batch_size,))\n",
    "minibatch = xs[minibatch_tensor]\n",
    "ys_minibatch = ys[minibatch_tensor]\n",
    "\n",
    "mlp = MLP(context_size, 10, 200)\n",
    "mlp.gradient_descent(minibatch,ys_minibatch,1000,0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4a3ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Getting an idea of how to choose a learning rate\n",
    "# lr_powers = torch.linspace(-3, 0, 2000)\n",
    "# lrs = 10**lr_powers\n",
    "# iter_count = 2000\n",
    "\n",
    "# #useful for plotting\n",
    "# lri, lossi = [], []\n",
    "\n",
    "# parameters =[mlp.C, mlp.W1, mlp.W2, mlp.H]\n",
    "\n",
    "# for i in range(iter_count):\n",
    "#     #forward pass\n",
    "#     logits = mlp.forward(minibatch)\n",
    "\n",
    "#     #compute loss\n",
    "#     loss = F.cross_entropy(logits, ys_minibatch)\n",
    "#     mlp.cross_entropy_loss = loss\n",
    "\n",
    "#     for p in parameters:\n",
    "#         p.grad = None\n",
    "\n",
    "#     #backward pass\n",
    "#     loss.backward()\n",
    "\n",
    "#     #choose lr\n",
    "#     lr = lrs[i]\n",
    "\n",
    "#     # update parameters\n",
    "#     for p in parameters:\n",
    "#         p.data-= lr*p.grad\n",
    "\n",
    "#     lri.append(lr.item())\n",
    "#     lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5569e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(lri, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos_dict = itos()\n",
    "stoi_dict = stoi()\n",
    "for _ in range(5):\n",
    "    c = \"\"\n",
    "    context = [\".\"]*context_size\n",
    "    word = \"\"\n",
    "    while c!=\".\":\n",
    "        word+=c\n",
    "        xs = torch.tensor([stoi_dict[c] for c in context])\n",
    "        logits = mlp.forward(xs=xs)\n",
    "        probs = logits.softmax(0)\n",
    "        sampled_char = itos_dict[torch.multinomial(probs, num_samples=1).item()]\n",
    "        context = context[1:] + [sampled_char]\n",
    "        c = sampled_char\n",
    "        done_iters-=1\n",
    "    print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_zero_to_hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
